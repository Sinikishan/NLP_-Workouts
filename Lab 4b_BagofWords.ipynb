{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTwFDx6ySScDK9lEtqMGKJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **BAG OF WORDS - Implementation**"],"metadata":{"id":"8ZNJCP0pV41F"}},{"cell_type":"markdown","source":["#  To implement a bag of words algorithm with Python.\n","This is a very basic implementation to understand how bag of words algorithm work, so I **would not recommend** using this in your project, instead use the method described in the next section."],"metadata":{"id":"AVUhDy1CTOBP"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQFIPnumSp2J","executionInfo":{"status":"ok","timestamp":1698479994666,"user_tz":-180,"elapsed":696,"user":{"displayName":"Sini kishan","userId":"05056090304666447450"}},"outputId":"65e0f685-d1bd-4020-fb41-62d74ac0fdac"},"outputs":[{"output_type":"stream","name":"stdout","text":["['welcome', 'to', 'nlp', 'learning', ',', 'now', 'start', 'learning']\n","['learning', 'is', 'a', 'good', 'practice']\n","['welcome', 'to', 'nlp', 'learning', ',', 'now', 'start', 'is', 'a', 'good', 'practice']\n","['welcome', 'nlp', 'learning', 'now', 'start', 'good', 'practice']\n","[1, 1, 2, 1, 1, 0, 0]\n","[0, 0, 1, 0, 0, 1, 1]\n"]}],"source":["def vectorize(tokens):\n","    ''' This function takes list of words in a sentence as input\n","    and returns a vector of size of filtered_vocab.It puts 0 if the\n","    word is not present in tokens and count of token if present.'''\n","    vector=[]\n","    for w in filtered_vocab:\n","        vector.append(tokens.count(w))\n","    return vector\n","def unique(sequence):\n","    '''This functions returns a list in which the order remains\n","    same and no item repeats.Using the set() function does not\n","    preserve the original ordering,so i didnt use that instead'''\n","    seen = set()\n","    return [x for x in sequence if not (x in seen or seen.add(x))]\n","#create a list of stopwords.You can import stopwords from nltk too\n","stopwords=[\"to\",\"is\",\"a\"]\n","#list of special characters.You can use regular expressions too\n","special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n","#Write the sentences in the corpus,in our case, just two\n","string1=\"Welcome to NLP Learning , Now start learning\"\n","string2=\"Learning is a good practice\"\n","#convert them to lower case\n","string1=string1.lower()\n","string2=string2.lower()\n","#split the sentences into tokens\n","tokens1=string1.split()\n","tokens2=string2.split()\n","print(tokens1)\n","print(tokens2)\n","#create a vocabulary list\n","vocab=unique(tokens1+tokens2)\n","print(vocab)\n","#filter the vocabulary list\n","filtered_vocab=[]\n","for w in vocab:\n","    if w not in stopwords and w not in special_char:\n","        filtered_vocab.append(w)\n","print(filtered_vocab)\n","#convert sentences into vectords\n","vector1=vectorize(tokens1)\n","print(vector1)\n","vector2=vectorize(tokens2)\n","print(vector2)"]},{"cell_type":"markdown","source":["References :\n","\n","[link text](https://www.mygreatlearning.com/blog/bag-of-words/#sh1)"],"metadata":{"id":"FL0dhzY-TB2E"}},{"cell_type":"markdown","source":["# **To Implement Bag of Words using SKLEARN Package **\n","\n","**CountVectorizer()** function from the Sk-learn library to easily implement the above BoW model using Python."],"metadata":{"id":"MUjhOh_cTsy2"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Define the input sentences\n","sentence_1 = \"This is a good job. I will not miss it for anything\"\n","sentence_2 = \"This is not good at all\"\n","\n","# Initialize the CountVectorizer with ngram_range and stop_words parameters\n","CountVec = CountVectorizer(ngram_range=(1, 1),  # Change to (2, 2) for bigrams\n","                          stop_words='english')\n","\n","# Transform the sentences\n","Count_data = CountVec.fit_transform([sentence_1, sentence_2])\n","\n","# Create a DataFrame to display the word counts\n","cv_dataframe = pd.DataFrame(Count_data.toarray(), columns=CountVec.get_feature_names_out())\n","\n","# Print the DataFrame\n","print(cv_dataframe)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgxWRe9ZTryj","executionInfo":{"status":"ok","timestamp":1698480699405,"user_tz":-180,"elapsed":390,"user":{"displayName":"Sini kishan","userId":"05056090304666447450"}},"outputId":"7bce36f0-50ae-485f-831a-a74deb091c75"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["   good  job  miss\n","0     1    1     1\n","1     1    0     0\n"]}]},{"cell_type":"markdown","source":["# **Implement Bag of words using NLTK package:**\n","\n","1. We start by importing the necessary libraries from NLTK.\n","2. We define a list of sample documents.\n","3. We tokenize the documents into words and convert them to lowercase.\n","4. We remove stopwords and punctuation from the tokens.\n","5. We create a vocabulary by collecting all unique words from the processed documents.\n","6. We initialize a BoW dictionary with word counts, setting the initial count for each word to 0.\n","7. We iterate through the filtered tokens and increment the count for each word in the BoW dictionary.\n","8. Finally, we print the BoW representation, which shows the word counts for each word in the vocabulary.\n","This code provides a basic example of how to create a Bag of Words representation using NLTK"],"metadata":{"id":"4dahVUoOVEpL"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1J41Kkt2Uqjf","executionInfo":{"status":"ok","timestamp":1698480461429,"user_tz":-180,"elapsed":384,"user":{"displayName":"Sini kishan","userId":"05056090304666447450"}},"outputId":"2f18924a-2356-48c6-b106-86fb8f4dba43"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from collections import Counter\n","\n","# Sample documents\n","documents = [\n","    \"I love natural language processing.\",\n","    \"Text classification is an important NLP task.\",\n","    \"NLTK provides useful tools for NLP.\",\n","]\n","\n","# Tokenization and lowercasing\n","tokens = [word_tokenize(doc.lower()) for doc in documents]\n","\n","# Remove stopwords and punctuation\n","stop_words = set(stopwords.words('english'))\n","filtered_tokens = [[word for word in token if word.isalnum() and word not in stop_words] for token in tokens]\n","\n","# Create a vocabulary\n","vocabulary = set(word for token in filtered_tokens for word in token)\n","\n","# Initialize a BoW dictionary with word counts\n","bow = {word: 0 for word in vocabulary}\n","\n","# Count word occurrences\n","for token in filtered_tokens:\n","    for word in token:\n","        bow[word] += 1\n","\n","# Print the BoW representation\n","print(\"Bag of Words (BoW) representation:\")\n","print(bow)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Faz_ubMZUkK_","executionInfo":{"status":"ok","timestamp":1698480465791,"user_tz":-180,"elapsed":1054,"user":{"displayName":"Sini kishan","userId":"05056090304666447450"}},"outputId":"15960712-88ff-4a76-ae4f-29ded02de6b5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Bag of Words (BoW) representation:\n","{'language': 1, 'love': 1, 'nlp': 2, 'useful': 1, 'text': 1, 'classification': 1, 'task': 1, 'important': 1, 'tools': 1, 'natural': 1, 'provides': 1, 'nltk': 1, 'processing': 1}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MJIp9czaTr6d"},"execution_count":null,"outputs":[]}]}